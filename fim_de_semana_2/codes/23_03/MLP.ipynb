{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5f9d5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from random import random\n",
    "\n",
    "# Code from: https://www.youtube.com/watch?v=0oWnheK-gGk and https://www.youtube.com/watch?v=Z97XGNUUx9o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d09b604",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "\n",
    "    def __init__(self, num_inputs=3, num_hidden=[3, 5], num_outputs=2):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "        layers = [self.num_inputs] + self.num_hidden + [self.num_outputs]\n",
    "\n",
    "        # Initiate random weights.\n",
    "        weights = []\n",
    "\n",
    "        for i in range(len(layers) - 1):\n",
    "            w = np.random.rand(layers[i], layers[i+1])\n",
    "            weights.append(w)\n",
    "\n",
    "        self.weights = weights\n",
    "\n",
    "        activations = []\n",
    "        for i in range(len(layers)):\n",
    "            a = np.zeros(layers[i])\n",
    "            activations.append(a)\n",
    "\n",
    "        self.activations = activations\n",
    "\n",
    "        derivatives = []\n",
    "        for i in range(len(layers) - 1): # Same number of weight matrices.\n",
    "            d = np.zeros((layers[i], layers[i+1]))\n",
    "            derivatives.append(d)\n",
    "\n",
    "        self.derivatives = derivatives\n",
    "\n",
    "\n",
    "    def forward_propagate(self, inputs):\n",
    "        activations = inputs\n",
    "        self.activations[0] = inputs\n",
    "\n",
    "        for i, w in enumerate(self.weights):\n",
    "            # Calculate net inputs.\n",
    "            net_inputs = np.dot(activations, w)\n",
    "            \n",
    "            # Calculate the activateions.\n",
    "            activations = self._sigmoid(net_inputs)\n",
    "            self.activations[i+1] = activations\n",
    "\n",
    "        return activations\n",
    "\n",
    "    def back_propagate(self, error, verbose=False):\n",
    "\n",
    "        for i in reversed(range(len(self.derivatives))):\n",
    "            activations = self.activations[i+1]\n",
    "            delta = error * self._sigmoid_derivative(activations)\n",
    "            delta_reshaped = delta.reshape(delta.shape[0], -1).T\n",
    "            current_activation = self.activations[i]\n",
    "            current_activation_reshaped = current_activation.reshape(current_activation.shape[0], -1)\n",
    "\n",
    "            self.derivatives[i] = np.dot(current_activation_reshaped, delta_reshaped)\n",
    "            error = np.dot(delta, self.weights[i].T)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Derivatives for W{i}: {self.derivatives[i]}\")\n",
    "\n",
    "        return error\n",
    "\n",
    "    def gradient_descent(self, learning_rate):\n",
    "\n",
    "        for i in range(len(self.weights)):\n",
    "            # weights = self.weights[i]\n",
    "            # derivatives = self.derivatives[i]\n",
    "            self.weights[i] += self.derivatives[i] * learning_rate\n",
    "\n",
    "    def train(self, inputs, targets, epochs, learning_rate):\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            sum_error = 0\n",
    "            for input, target in zip(inputs, targets):\n",
    "                # Perform forward prop.\n",
    "                output = self.forward_propagate(input)\n",
    "\n",
    "                # Calculate error.\n",
    "                error = target - output\n",
    "\n",
    "                self.back_propagate(error)#, verbose=True)\n",
    "\n",
    "                # Apply Gradient Descent\n",
    "                self.gradient_descent(learning_rate)\n",
    "\n",
    "                sum_error += self._mse(target, output)\n",
    "                        \n",
    "            # Report error.\n",
    "            print(f\"Error {sum_error/len(inputs)} at epoch {i}\")\n",
    "\n",
    "    def _mse(self, target, output):\n",
    "        return np.average((target - output)**2)\n",
    "\n",
    "    def _sigmoid_derivative(self, x):\n",
    "        return x * (1.0 - x)\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6f15069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 0.3634076875567096 at epoch 0\n",
      "Error 0.36224191579891624 at epoch 1\n",
      "Error 0.36107964625236194 at epoch 2\n",
      "Error 0.3599209624042558 at epoch 3\n",
      "Error 0.3587659468108481 at epoch 4\n",
      "Error 0.3576146810652342 at epoch 5\n",
      "Error 0.3564672457658529 at epoch 6\n",
      "Error 0.3553237204857131 at epoch 7\n",
      "Error 0.3541841837423724 at epoch 8\n",
      "Error 0.35304871296869905 at epoch 9\n",
      "Error 0.35191738448443977 at epoch 10\n",
      "Error 0.3507902734686219 at epoch 11\n",
      "Error 0.3496674539328097 at epoch 12\n",
      "Error 0.348548998695241 at epoch 13\n",
      "Error 0.34743497935586276 at epoch 14\n",
      "Error 0.3463254662722863 at epoch 15\n",
      "Error 0.34522052853668156 at epoch 16\n",
      "Error 0.3441202339536257 at epoch 17\n",
      "Error 0.3430246490189236 at epoch 18\n",
      "Error 0.341933838899414 at epoch 19\n",
      "Error 0.3408478674137737 at epoch 20\n",
      "Error 0.339766797014332 at epoch 21\n",
      "Error 0.33869068876990577 at epoch 22\n",
      "Error 0.3376196023496632 at epoch 23\n",
      "Error 0.3365535960080227 at epoch 24\n",
      "Error 0.3354927265705957 at epoch 25\n",
      "Error 0.33443704942117364 at epoch 26\n",
      "Error 0.3333866184897649 at epoch 27\n",
      "Error 0.3323414862416833 at epoch 28\n",
      "Error 0.3313017036676853 at epoch 29\n",
      "[0.67077673]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Create an MLP.\n",
    "mlp = MLP(2, [5], 1)\n",
    "\n",
    "# Create a dataset to train a network for the sum operation.\n",
    "#inputs = np.array([[random()/2 for _ in range(2)] for _ in range(1000)])\n",
    "#targets = np.array([[i[0] + i[1]] for i in inputs])\n",
    "\n",
    "inputs = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "targets = np.array([0,0,0,1])\n",
    "\n",
    "# Train our model.\n",
    "mlp.train(inputs, targets, 30, 0.01)\n",
    "result = mlp.forward_propagate(np.array([1,1]))\n",
    "print(result)\n",
    "print(int(np.round(result)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
